{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Transfer Stacking\n",
    "def Ffold_cross_val(Xtrain, Ytrain, F, estimator):\n",
    "# KFold\n",
    "    row_Xtrain = Xtrain.shape[0]\n",
    "    # 创建一个 KFold 对象，设置折数为 5\n",
    "    kf = KFold(n_splits=F)\n",
    "    # 使用 KFold 对象划分数据集，并进行交叉验证\n",
    "    output = np.zeros(row_Xtrain, 1)\n",
    "    for train_index, val_index in kf.split(Xtrain):\n",
    "        x_train, x_val = [Xtrain[i] for i in train_index], [Xtrain[i] for i in val_index]\n",
    "        y_train, _ = [Ytrain[i] for i in train_index], [Ytrain[i] for i in val_index]\n",
    "        estimator.fit(x_train, y_train)\n",
    "        output[val_index] = estimator.predict(x_val)\n",
    "    return output\n",
    "def TransferStacking(Xmsource, Xtarget, Ymsource, Ytarget, Xtest, *kargs):\n",
    "    \"\"\"\n",
    "    Transfer Stacking\n",
    "    parameter\n",
    "    _________\n",
    "    Xmsource = dict{source1: A,\n",
    "                    source2: B,\n",
    "                    ...}\n",
    "    Xtarget - matrix\n",
    "    Ymsource = dict{source1: A,\n",
    "                    source2: B.\n",
    "                    ...}\n",
    "    Ytarget - vector\n",
    "    Xtest\n",
    "\n",
    "    Atrributes\n",
    "    ----------\n",
    "    \n",
    "    return\n",
    "    ------\n",
    "    \"\"\"\n",
    "    Xmsource = list(Xmsource.values())\n",
    "    Xsource = np.concatenate(Xmsource)\n",
    "    Xtrain = np.concatenate([Xsource, Xtarget], axis=0)\n",
    "    Ymsource = list(Ymsource.value())\n",
    "    Ysource = np.concatenate(Ymsource)\n",
    "    Ytrain = np.concatenate([Ysource, Ytarget], axis=0)\n",
    "    \n",
    "    num_source = len(Xmsource)\n",
    "    row_Xtrain = Xtrain.shape[0]\n",
    "    output = np.zeros(row_Xtrain, num_source)\n",
    "    estimators = []\n",
    "    for i in range(num_source):\n",
    "        estimator = DecisionTreeClassifier(criterion='gini',max_depth=3, random_state=42)\n",
    "        estimator.fit(Xmsource[i], Ymsource[i])\n",
    "        output[:,i] = estimator.predict(Xtrain)\n",
    "        estimators.append(estimator)\n",
    "    \n",
    "    reg = DecisionTreeClassifier(max_depth=2,splitter='random',max_features=\"log2\",random_state=0)\n",
    "    estimators.append(reg)\n",
    "\n",
    "    output_cv = Ffold_cross_val(Xtrain, Ytrain, 5, reg)\n",
    "    meta_feature = np.concatenate([output, output_cv], axis=1)\n",
    "    \n",
    "\n",
    "    linearR = LinearRegression()\n",
    "    linearR.fit(meta_feature, Ytrain)\n",
    "    print('The linear combination of hypothesis is founded:')\n",
    "    print('coef:', linearR.coef_ ,'|| intercept :', linearR.intercept_)\n",
    "    hypothesis = np.zeros(row_Xtrain, len(estimators))\n",
    "    for j in range(len(estimators)):\n",
    "        hypothesis[:,j] = estimators[j].predict(Xtest)\n",
    "\n",
    "    coef = linearR.coef_\n",
    "    intercept = linearR.intercept_\n",
    "    predict = np.ones(row_Xtrain)*intercept\n",
    "    for i in range(len(coef)):\n",
    "        predict += coef[j]*hypothesis[:,j]\n",
    "    return predict\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TransferStacking() missing 2 required positional arguments: 'Ymsource' and 'Ytarget'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m my_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mkey1\u001b[39m\u001b[39m'\u001b[39m: [[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m],[\u001b[39m10\u001b[39m,\u001b[39m11\u001b[39m,\u001b[39m12\u001b[39m]],\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mkey2\u001b[39m\u001b[39m'\u001b[39m: [[\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m], [\u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m]],\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m], [\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m]])\n\u001b[0;32m----> 6\u001b[0m TransferStacking(my_dict, x)\n",
      "\u001b[0;31mTypeError\u001b[0m: TransferStacking() missing 2 required positional arguments: 'Ymsource' and 'Ytarget'"
     ]
    }
   ],
   "source": [
    "my_dict = {\n",
    "    'key1': [[1, 2, 3],[10,11,12]],\n",
    "    'key2': [[4, 5, 6], [7, 8, 9]],\n",
    "}\n",
    "x = np.array([[1,1,1], [2, 2, 2]])\n",
    "TransferStacking(my_dict, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [10, 11, 12],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.concatenate(list(my_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [2 3 4 5 6 7 8 9]\n",
      "Test: [0 1]\n",
      "\n",
      "Train: [0 1 4 5 6 7 8 9]\n",
      "Test: [2 3]\n",
      "\n",
      "Train: [0 1 2 3 6 7 8 9]\n",
      "Test: [4 5]\n",
      "\n",
      "Train: [0 1 2 3 4 5 8 9]\n",
      "Test: [6 7]\n",
      "\n",
      "Train: [0 1 2 3 4 5 6 7]\n",
      "Test: [8 9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 假设有一个数据集 X 和对应的标签 y\n",
    "X = [11, 21, 31, 41, 13, 6, 7, 8, 9, 10]\n",
    "y = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "\n",
    "# 创建一个 KFold 对象，设置折数为 5\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# 使用 KFold 对象划分数据集，并进行交叉验证\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "    y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "\n",
    "    # 输出训练集和测试集的索引\n",
    "    print(\"Train:\", train_index)\n",
    "    print(\"Test:\", test_index)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transfer_Stacking(trans_S, Multi_trans_A, response_S, Multi_response_A, test,):\n",
    "    \"\"\"Boosting for Regression Transfer\n",
    "\n",
    "    Please feel free to open issues in the Github : https://github.com/Bin-Cao/TrAdaboost\n",
    "    or \n",
    "    contact Bin Cao (bcao@shu.edu.cn)\n",
    "    in case of any problems/comments/suggestions in using the code. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trans_S : feature matrix of same-distribution training data\n",
    "\n",
    "    Multi_trans_A : dict, feature matrix of diff-distribution training data\n",
    "    e.g.,\n",
    "    Multi_trans_A = {\n",
    "    'trans_A_1' :  data_1 , \n",
    "    'trans_A_2' : data_2 ,\n",
    "    ......\n",
    "    }\n",
    "\n",
    "    response_S : responses of same-distribution training data, real number\n",
    "\n",
    "    Multi_response_A : dict, responses of diff-distribution training data, real number\n",
    "    e.g.,\n",
    "    Multi_response_A = {\n",
    "    'response_A_1' :  response_1 , \n",
    "    'response_A_2' : response_2 ,\n",
    "    ......\n",
    "    }\n",
    "\n",
    "    test : feature matrix of test data\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    # same-distribution training data\n",
    "    tarin_data = pd.read_csv('M_Sdata.csv')\n",
    "    # two diff-distribution training data\n",
    "    A1_tarin_data = pd.read_csv('M_Adata1.csv')\n",
    "    A2_tarin_data = pd.read_csv('M_Adata2.csv')\n",
    "    # test data\n",
    "    test_data = pd.read_csv('M_Tdata.csv')\n",
    "\n",
    "    Multi_trans_A = {\n",
    "    'trans_A_1' : A1_tarin_data.iloc[:,:-1],\n",
    "    'trans_A_2' : A2_tarin_data.iloc[:,:-1]\n",
    "    }\n",
    "    Multi_response_A = {\n",
    "    'response_A_1' :  A1_tarin_data.iloc[:,-1] , \n",
    "    'response_A_2' :  A2_tarin_data.iloc[:,-1] ,\n",
    "    }\n",
    "    trans_S = tarin_data.iloc[:,:-1]\n",
    "    response_S = tarin_data.iloc[:, -1]\n",
    "    test = test_data.iloc[:,:-1]\n",
    " \n",
    "    Transfer_Stacking(trans_S, Multi_trans_A, response_S, Multi_response_A, test,)\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Pardoe, D., & Stone, P. (2010, June). \n",
    "    Boosting for regression transfer. \n",
    "    In Proceedings of the 27th International Conference \n",
    "    on International Conference on Machine Learning (pp. 863-870).\n",
    "\n",
    "    \"\"\"\n",
    "    # generate a pool of experts according the diff-dis datasets\n",
    "    weak_classifiers_set = []\n",
    "    reg = DecisionTreeRegressor(max_depth=2,splitter='random',max_features=\"log2\",random_state=0)\n",
    "    for source in range(len(Multi_trans_A)):\n",
    "        trans_A = list(Multi_trans_A.values())[source]\n",
    "        response_A = list(Multi_response_A.values())[source]\n",
    "\n",
    "        trans_A = np.asarray(trans_A, order='C')\n",
    "        response_A = np.asarray(response_A, order='C')\n",
    "\n",
    "        weak_classifier = reg.fit(trans_A, response_A, )\n",
    "        weak_classifiers_set.append(weak_classifier)\n",
    "    print('A set of experts is initilized and contains {} classifier'.format(len(weak_classifiers_set)))\n",
    "    print('='*60)\n",
    "\n",
    "    row_S = trans_S.shape[0]\n",
    "    row_T = test.shape[0]\n",
    "    print ('params initial finished.')\n",
    "\n",
    "    X = np.array(trans_S)\n",
    "    Y = np.array(response_S)\n",
    "    LOOCV_LS_matrix = np.ones([row_S, len(weak_classifiers_set)+1])\n",
    "    LOOCV_LS_matrix[:,-1] = LOOCV_output(X,Y)\n",
    "    for j in range(len(weak_classifiers_set)):\n",
    "        LOOCV_LS_matrix[:,j] = weak_classifiers_set[j].predict(X)\n",
    "    \n",
    "    # find the linear combination of hypotheses that minimizes squared error.\n",
    "    reg = LinearRegression().fit(LOOCV_LS_matrix, Y)\n",
    "    print('The linear combination of hypotheses is founded:')\n",
    "    print('coef:', reg.coef_ ,'|| intercept :', reg.intercept_)\n",
    "    coef = reg.coef_\n",
    "    intercept = reg.intercept_\n",
    "    # add the newly clf into the set\n",
    "    weak_classifiers_set.append(reg.fit(X, Y))\n",
    "\n",
    "    # save the prediction results of weak classifiers\n",
    "    result_response = np.ones([row_T, len(weak_classifiers_set)])\n",
    "    for item in range(len(weak_classifiers_set)):\n",
    "        result_response[:,item] = weak_classifiers_set[item].predict(np.array(test))\n",
    "    predict = np.ones(row_T) * intercept\n",
    "    for j in range(len(coef)):\n",
    "        predict += coef[j] * result_response[:,j]\n",
    "    print('Transfer_Stacking is done')\n",
    "    print('='*60)\n",
    "    print('The prediction responses of test data are :')\n",
    "    print(predict)\n",
    "    return predict\n",
    "\n",
    "\n",
    "def LOOCV_output(X,Y):\n",
    "    loo = LeaveOneOut()\n",
    "    reg = DecisionTreeRegressor(max_depth=2,splitter='random',max_features=\"log2\",random_state=0)\n",
    "    y_pre_loocv = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, _ = Y[train_index], Y[test_index]\n",
    "        weak_classifier_new = reg.fit(X_train, y_train)\n",
    "        y_pre = weak_classifier_new.predict(X_test)\n",
    "        y_pre_loocv.append(y_pre)\n",
    "    return y_pre_loocv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'A': 1, 'B': 2, 'C': 3}\n",
    "for i in range(2):\n",
    "    first_key = next(iter(my_dict))\n",
    "    first_value = my_dict[first_key]\n",
    "\n",
    "    print(first_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11. 13.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# 创建训练数据\n",
    "X = np.array([[1], [2], [3], [4]])\n",
    "y = np.array([3, 5, 7, 9])\n",
    "\n",
    "# 创建线性回归模型并进行训练\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# 进行预测\n",
    "X_test = np.array([[5], [6]])\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999982"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11. 13.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# 创建训练数据\n",
    "X = np.array([[1, 2], [2, 4], [3, 6], [4, 8]])  # 多维特征\n",
    "y = np.array([3, 5, 7, 9])\n",
    "\n",
    "# 创建线性回归模型并进行训练\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# 进行预测\n",
    "X_test = np.array([[5, 10], [6, 12]])  # 新的测试数据\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999991"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "non_dominated_sorting() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m Ytrain \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:,\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[0;32m      9\u001b[0m mobo \u001b[39m=\u001b[39m Mobo4mat()\n\u001b[1;32m---> 11\u001b[0m mobo\u001b[39m.\u001b[39;49mfit(X \u001b[39m=\u001b[39;49m Xtrain, y \u001b[39m=\u001b[39;49m Ytrain, visual_data\u001b[39m=\u001b[39;49mXtrain, method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mHV\u001b[39;49m\u001b[39m'\u001b[39;49m,number\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, objective\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m, ref_point\u001b[39m=\u001b[39;49m[\u001b[39m10\u001b[39;49m, \u001b[39m10\u001b[39;49m])\n",
      "File \u001b[1;32mf:\\Github\\MOBO\\mobo.py:36\u001b[0m, in \u001b[0;36mMobo4mat.fit\u001b[1;34m(self, X, y, visual_data, method, number, objective, ref_point)\u001b[0m\n\u001b[0;32m     33\u001b[0m target_names \u001b[39m=\u001b[39m Ytrain\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m objective \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m     pareto_front \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_non_dominated_solutions(Xtrain, target_names)\n\u001b[0;32m     37\u001b[0m     pareto_front \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(pareto_front, columns\u001b[39m=\u001b[39mtarget_names)\n\u001b[0;32m     39\u001b[0m     kernel \u001b[39m=\u001b[39m RBF(length_scale\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n",
      "File \u001b[1;32mf:\\Github\\MOBO\\mobo.py:124\u001b[0m, in \u001b[0;36mMobo4mat.find_non_dominated_solutions\u001b[1;34m(self, fitness_values, feature_name)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_non_dominated_solutions\u001b[39m(\u001b[39mself\u001b[39m, fitness_values, feature_name):\n\u001b[1;32m--> 124\u001b[0m     frontiers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_dominated_sorting(fitness_values)\n\u001b[0;32m    125\u001b[0m     non_dominated_solutions_idx \u001b[39m=\u001b[39m []\n\u001b[0;32m    126\u001b[0m     \u001b[39mfor\u001b[39;00m frontier \u001b[39min\u001b[39;00m frontiers:\n",
      "\u001b[1;31mTypeError\u001b[0m: non_dominated_sorting() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from mobo import Mobo4mat\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
